# -*- coding: utf-8 -*-
"""classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QBnEIfITjiSybZNZ6J1CA_5LoPfr_eiD
"""
#!pip install spacy


import pandas as pd

df=pd.read_csv('C:/Users/akshi/Downloads/LLM prj 2/DATA-malaymail/news_data_cleaned.csv')

import nltk
nltk.download('vader_lexicon')

from nltk.sentiment import SentimentIntensityAnalyzer

# Initialize VADER SentimentIntensityAnalyzer
sia = SentimentIntensityAnalyzer()

# Function to perform sentiment analysis
def analyze_sentiment(text):
    try:
        if not text:
            return None
        sentiment_scores = sia.polarity_scores(text)
        return sentiment_scores
    except Exception as e:
        print(f"Error analyzing sentiment: {e}")
        return None

# Apply sentiment analysis to the DataFrame
df['Sentiment Scores'] = df['Cleaned Article Text'].apply(
    lambda text: analyze_sentiment(text) if isinstance(text, str) and text.strip() else None
)

# Extract individual sentiment scores into separate columns
df['Negative Sentiment'] = df['Sentiment Scores'].apply(lambda x: x['neg'] if x else None)
df['Neutral Sentiment'] = df['Sentiment Scores'].apply(lambda x: x['neu'] if x else None)
df['Positive Sentiment'] = df['Sentiment Scores'].apply(lambda x: x['pos'] if x else None)
df['Compound Sentiment'] = df['Sentiment Scores'].apply(lambda x: x['compound'] if x else None)

# Categorize sentiment based on compound score
def categorize_sentiment(compound_score):
    if compound_score >= 0.05:
        return "Positive"
    elif compound_score <= -0.05:
        return "Negative"
    else:
        return "Neutral"

df['Sentiment Category'] = df['Compound Sentiment'].apply(
    lambda score: categorize_sentiment(score) if score is not None else None
)

# Display the DataFrame with sentiment analysis
print(df[['Cleaned Title', 'Cleaned Article Text', 'Sentiment Category']].head())

# Save the DataFrame with sentiment analysis results
df.to_csv("sentiment_analysis_results.csv", index=False)
print("Sentiment analysis results saved to sentiment_analysis_results.csv")
# Count the number of occurrences for each sentiment category
sentiment_counts = df['Sentiment Category'].value_counts()
print("Sentiment Counts:")
print(sentiment_counts)

# Extract counts for each category
num_positive = sentiment_counts.get('Positive', 0)
num_negative = sentiment_counts.get('Negative', 0)
num_neutral = sentiment_counts.get('Neutral', 0)

print(f"Number of Positive: {num_positive}")
print(f"Number of Negative: {num_negative}")
print(f"Number of Neutral: {num_neutral}")

from textblob import TextBlob

# Function to perform sentiment analysis
def analyze_sentiment(text):
    try:
        # Create a TextBlob object
        blob = TextBlob(text)

        # Extract polarity and subjectivity
        polarity = blob.sentiment.polarity  # Ranges from -1 (negative) to 1 (positive)
        subjectivity = blob.sentiment.subjectivity  # Ranges from 0 (objective) to 1 (subjective)

        return polarity, subjectivity
    except Exception as e:
        print(f"Error analyzing sentiment: {e}")
        return None, None

# Assuming 'df' is your DataFrame and 'Preprocessed Article' is the column to analyze
df['Polarity'], df['Subjectivity'] = zip(*df['Cleaned Article Text'].apply(analyze_sentiment))

# Display the DataFrame with polarity and subjectivity
print(df[['Cleaned Title', 'Polarity', 'Subjectivity']].head())
sentiment_counts = df['Subjectivity'].value_counts()
print("Sentiment Counts:")
print(sentiment_counts)

# Extract counts for each category
num_positive = sentiment_counts.get('Positive', 0)
num_negative = sentiment_counts.get('Negative', 0)
num_neutral = sentiment_counts.get('Neutral', 0)

print(f"Number of Positive: {num_positive}")
print(f"Number of Negative: {num_negative}")
print(f"Number of Neutral: {num_neutral}")

#!pip install vaderSentiment

import spacy
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# Load the spaCy model
import spacy

nlp = spacy.load("en_core_web_sm")

# Initialize the VADER sentiment intensity analyzer
analyzer = SentimentIntensityAnalyzer()

# Function to perform sentiment analysis
def analyze_sentiment_spacy(text):
    try:
        # Use spaCy to process the text
        doc = nlp(text)

        # VADER sentiment analysis
        sentiment = analyzer.polarity_scores(text)

        # Extract polarity and subjectivity from VADER results
        polarity = sentiment['compound']  # Compound score represents the overall sentiment
        subjectivity = doc.sentiment if hasattr(doc, 'sentiment') else None

        # VADER 'compound' score ranges from -1 (negative) to 1 (positive)
        return polarity, subjectivity
    except Exception as e:
        print(f"Error analyzing sentiment: {e}")
        return None, None

# Assuming 'df' is your DataFrame and 'Preprocessed Article' is the column to analyze
df['polarity'], df['subjectivity'] = zip(*df['Cleaned Article Text'].apply(analyze_sentiment_spacy))

# Display the DataFrame with polarity and subjectivity
print(df[['Cleaned Title', 'polarity', 'subjectivity']].head())
sentiment_counts = df['subjectivity'].value_counts()
print("Sentiment Counts:")
print(sentiment_counts)

# Extract counts for each category
num_positive = sentiment_counts.get('Positive', 0)
num_negative = sentiment_counts.get('Negative', 0)
num_neutral = sentiment_counts.get('Neutral', 0)

print(f"Number of Positive: {num_positive}")
print(f"Number of Negative: {num_negative}")
print(f"Number of Neutral: {num_neutral}")

df=pd.read_csv('C:/Users/akshi/Downloads/LLM/sentiment_analysis_results.csv')

# classification using svm
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
import pandas as pd

# Assuming 'df' is the DataFrame containing the data
X = df["Cleaned Article Text"]
y = df["Sentiment Category"]  # Assuming this column contains 'Positive', 'Neutral', 'Negative' categories

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Text vectorization (TF-IDF)
vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=5, max_df=0.7, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Balancing the dataset using SMOTE
# Balancing the dataset using SMOTE
smote = SMOTE(random_state=42, k_neighbors=min(5, y_train.value_counts().min() - 1)) # Change is here
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)
# SVM model with hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 10],  # Regularization strength
    'kernel': ['linear', 'rbf'],  # Kernel types
    'gamma': ['scale', 'auto']  # Kernel coefficient
}

grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_balanced, y_train_balanced)

# Best model and parameters
best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)


# Model evaluation
y_pred = best_model.predict(X_test_tfidf)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
# Test Accuracy
test_accuracy = best_model.score(X_test_tfidf, y_test)
print("\nTest Accuracy:", test_accuracy)


# Model accuracy
accuracy = best_model.score(X_test_tfidf, y_test)
print("\nModel Accuracy:", accuracy)
# Train Accuracy
train_accuracy = best_model.score(X_train_tfidf, y_train)
print("\nTrain Accuracy:", train_accuracy)

# classification using LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
import pandas as pd

# Assuming 'df' is the DataFrame containing the data
X = df["Cleaned Article Text"]
y = df["Sentiment Category"]  # Assuming this column contains 'Positive', 'Neutral', 'Negative' categories

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Text vectorization (TF-IDF)
vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=5, max_df=0.7, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Balancing the dataset using SMOTE
smote = SMOTE(random_state=42, k_neighbors=min(5, y_train.value_counts().min() - 1))  # Balancing with SMOTE
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)

# Logistic Regression model with hyperparameter tuning
param_grid = {
    'C': [0.1, 1, 10],  # Regularization strength
    'penalty': ['l2'],  # Regularization type
    'solver': ['liblinear', 'saga']  # Solvers
}

grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_balanced, y_train_balanced)

# Best model and parameters
best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Test Accuracy
test_accuracy = best_model.score(X_test_tfidf, y_test)
print("\nTest Accuracy:", test_accuracy)
# Model evaluation
y_pred = best_model.predict(X_test_tfidf)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))


# Model accuracy
accuracy = best_model.score(X_test_tfidf, y_test)
print("\nModel Accuracy:", accuracy)
# Train Accuracy
train_accuracy = best_model.score(X_train_tfidf, y_train)
print("\nTrain Accuracy:", train_accuracy)

# classification using naive bayes
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
import pandas as pd

# Assuming 'df' is the DataFrame containing the data
X = df["Cleaned Article Text"]
y = df["Sentiment Category"]  # Assuming this column contains 'Positive', 'Neutral', 'Negative' categories

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Text vectorization (TF-IDF)
vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=5, max_df=0.7, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Balancing the dataset using SMOTE
smote = SMOTE(random_state=42, k_neighbors=min(5, y_train.value_counts().min() - 1))  # Balancing with SMOTE
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)

# Naive Bayes model with hyperparameter tuning
param_grid = {
    'alpha': [0.1, 1, 10],  # Smoothing parameter
}

grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_balanced, y_train_balanced)

# Best model and parameters
best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Model evaluation
y_pred = best_model.predict(X_test_tfidf)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Model accuracy
accuracy = best_model.score(X_test_tfidf, y_test)
print("\nModel Accuracy:", accuracy)
# Test Accuracy
test_accuracy = best_model.score(X_test_tfidf, y_test)
print("\nTest Accuracy:", test_accuracy)
# Train Accuracy
train_accuracy = best_model.score(X_train_tfidf, y_train)
print("\nTrain Accuracy:", train_accuracy)

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
import pandas as pd

# Assuming 'df' is the DataFrame containing the data
X = df["Cleaned Article Text"]
y = df["Sentiment Category"]  # Assuming this column contains 'Positive', 'Neutral', 'Negative' categories

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Text vectorization (TF-IDF)
vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=5, max_df=0.7, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Balancing the dataset using SMOTE
smote = SMOTE(random_state=42, k_neighbors=min(5, y_train.value_counts().min() - 1))  # Balancing with SMOTE
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)

# Random Forest model with hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 150],  # Number of trees in the forest
    'max_depth': [None, 10, 20],  # Depth of each tree
    'min_samples_split': [2, 5],  # Minimum samples required to split a node
    'min_samples_leaf': [1, 2],  # Minimum samples required at a leaf node
    'bootstrap': [True, False]  # Whether to use bootstrap sampling
}

grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_balanced, y_train_balanced)

# Best model and parameters
best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Model evaluation
y_pred = best_model.predict(X_test_tfidf)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Model accuracy
accuracy = best_model.score(X_test_tfidf, y_test)
print("\nModel Accuracy:", accuracy)
# Test Accuracy
test_accuracy = best_model.score(X_test_tfidf, y_test)
print("\nTest Accuracy:", test_accuracy)
# Train Accuracy
train_accuracy = best_model.score(X_train_tfidf, y_train)
print("\nTrain Accuracy:", train_accuracy)

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
import pandas as pd

# Assuming 'df' is the DataFrame containing the data
X = df["Cleaned Article Text"]
y = df["Sentiment Category"]  # Assuming this column contains 'Positive', 'Neutral', 'Negative' categories

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Text vectorization (TF-IDF)
vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000, min_df=5, max_df=0.7, stop_words='english')
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Balancing the dataset using SMOTE
smote = SMOTE(random_state=42, k_neighbors=min(5, y_train.value_counts().min() - 1))  # Balancing with SMOTE
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_tfidf, y_train)

# Decision Tree model with hyperparameter tuning
param_grid = {
    'max_depth': [None, 10, 20],  # Depth of the tree
    'min_samples_split': [2, 10],  # Minimum samples required to split a node
    'min_samples_leaf': [1, 2],  # Minimum samples required at a leaf node
    'criterion': ['gini', 'entropy']  # Function to measure quality of split
}

grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')
grid_search.fit(X_train_balanced, y_train_balanced)

# Best model and parameters
best_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Model evaluation
y_pred = best_model.predict(X_test_tfidf)
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

# Model accuracy
accuracy = best_model.score(X_test_tfidf, y_test)
print("\nModel Accuracy:", accuracy)
# Test Accuracy
test_accuracy = best_model.score(X_test_tfidf, y_test)
print("\nTest Accuracy:", test_accuracy)
# Train Accuracy
train_accuracy = best_model.score(X_train_tfidf, y_train)
print("\nTrain Accuracy:", train_accuracy)

"""Save the svm model

"""

# Save the trained model and vectorizer using joblib
import joblib
joblib.dump(best_model, 'svm_sentiment_model.pkl')
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')